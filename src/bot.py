# src/bot.py
import os
import json
import logging
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters, ConversationHandler
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from dotenv import load_dotenv
# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è OpenAI
from openai import OpenAI, APIError, RateLimitError, AuthenticationError

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
load_dotenv()

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_NAME = 'intfloat/multilingual-e5-large'
FAISS_INDEX_PATH = 'models/faiss_index.bin'
CHUNKS_PATH = 'models/chunks.json'
DATA_FILE_PATH = 'data/programs_data.json'

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
model = None
index = None
chunks = None
programs_data = None
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = None

# --- –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π ---
BACKGROUND, INTERESTS, CAREER = range(3)

# --- –°–æ–æ–±—â–µ–Ω–∏—è –±–æ—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º ---
START_MESSAGE = (
    "ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø —á–∞—Ç-–±–æ—Ç –¥–ª—è –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤ –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä –ò–¢–ú–û –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º AI.\n\n"
    "–Ø –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–≥—Ä–∞–º–º–∞—Ö:\n"
    "üîπ '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç'\n"
    "üîπ 'AI –∏ ML –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö'\n\n"
    "–ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–π –º–Ω–µ –≤–æ–ø—Ä–æ—Å!\n\n"
    "–•–æ—á–µ—à—å —É–∑–Ω–∞—Ç—å, –∫–∞–∫–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ —Ç–µ–±–µ –±–æ–ª—å—à–µ –ø–æ–¥—Ö–æ–¥–∏—Ç? –ù–∞–ø–∏—à–∏ /recommend."
)

RECOMMEND_START_MESSAGE = (
    "–î–∞–≤–∞–π –ø–æ–¥–±–µ—Ä—É —Ç–µ–±–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤.\n\n"
    "1Ô∏è‚É£ –ö–∞–∫–æ–π —É —Ç–µ–±—è –±—ç–∫–≥—Ä–∞—É–Ω–¥? (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞, —Ñ–∏–∑–∏–∫–∞, —ç–∫–æ–Ω–æ–º–∏–∫–∞)"
)
RECOMMEND_INTERESTS_MESSAGE = "2Ô∏è‚É£ –ö–∞–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ –ò–ò —Ç–µ–±–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ? (–Ω–∞–ø—Ä–∏–º–µ—Ä, Computer Vision, NLP, Reinforcement Learning, Data Engineering, AI Product)"
RECOMMEND_CAREER_MESSAGE = "3Ô∏è‚É£ –ö–∞–∫—É—é –∫–∞—Ä—å–µ—Ä—É —Ç—ã —Ö–æ—á–µ—à—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å? (–Ω–∞–ø—Ä–∏–º–µ—Ä, ML Engineer, Data Scientist, AI Product Manager, Data Analyst)"
RECOMMEND_RESULT_MESSAGE = (
    "–ù–∞ –æ—Å–Ω–æ–≤–µ —Ç–≤–æ–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤:\n"
    "- –ë—ç–∫–≥—Ä–∞—É–Ω–¥: {background}\n"
    "- –ò–Ω—Ç–µ—Ä–µ—Å—ã: {interests}\n"
    "- –ö–∞—Ä—å–µ—Ä–Ω–∞—è —Ü–µ–ª—å: {career_goal}\n\n"
    "üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: *{recommended_program}*\n"
    "üìå –ü—Ä–∏—á–∏–Ω–∞: {reason}\n\n"
    "–¢–µ–ø–µ—Ä—å —Ç—ã –º–æ–∂–µ—à—å –∑–∞–¥–∞—Ç—å –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã –æ–± —ç—Ç–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ!"
)
RECOMMEND_CANCEL_MESSAGE = "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –ú–æ–∂–µ—à—å –∑–∞–¥–∞—Ç—å –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–≥—Ä–∞–º–º–∞—Ö."

# --- –°–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ OpenAI API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω ---
NO_LLM_MESSAGE = (
    "–ë–æ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –Ω–æ API-–∫–ª—é—á –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ (OpenAI) –Ω–µ –Ω–∞–π–¥–µ–Ω.\n"
    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ `OPENAI_API_KEY` –≤ —Ñ–∞–π–ª–µ `.env` –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã.\n"
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥—ã–¥—É—â—É—é –≤–µ—Ä—Å–∏—é –±–æ—Ç–∞ –±–µ–∑ LLM."
)

# --- –°–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö API ---
LLM_API_ERROR_MESSAGE = "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ —Å–µ—Ä–≤–∏—Å—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ–∑–∂–µ."
LLM_AUTH_ERROR_MESSAGE = "–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å API –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –±–æ—Ç–∞."
LLM_RATE_LIMIT_MESSAGE = "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —Å–µ—Ä–≤–∏—Å—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start."""
    await context.bot.send_message(chat_id=update.effective_chat.id, text=START_MESSAGE, parse_mode='Markdown')

# --- –õ–æ–≥–∏–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
async def recommend_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(RECOMMEND_START_MESSAGE)
    return BACKGROUND

async def recommend_background(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data['background'] = update.message.text
    await update.message.reply_text(RECOMMEND_INTERESTS_MESSAGE)
    return INTERESTS

async def recommend_interests(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data['interests'] = update.message.text
    await update.message.reply_text(RECOMMEND_CAREER_MESSAGE)
    return CAREER

async def recommend_career(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data['career_goal'] = update.message.text
    
    background = context.user_data.get('background', '').lower()
    interests = context.user_data.get('interests', '').lower()
    career_goal = context.user_data.get('career_goal', '').lower()

    ai_keywords = ['ml engineer', 'data engineer', 'data scientist', 'computer vision', 'nlp', 'reinforcement learning', '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ', '–≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ', '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏', '–∞–ª–≥–æ—Ä–∏—Ç–º—ã', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', ' middle', 'middle']
    ai_product_keywords = ['product manager', 'ai product', 'product', '–±–∏–∑–Ω–µ—Å', '–∞–Ω–∞–ª–∏—Ç–∏–∫', 'data analyst', '—Å–∏—Å—Ç–µ–º–Ω—ã–π –ø–æ–¥—Ö–æ–¥', '—ç–∫–æ–Ω–æ–º–∏–∫–∞', '–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç', '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏', 'developer']

    ai_score = sum(1 for keyword in ai_keywords if keyword in interests or keyword in career_goal or keyword in background)
    ai_product_score = sum(1 for keyword in ai_product_keywords if keyword in interests or keyword in career_goal or keyword in background)

    if ai_score > ai_product_score:
        recommended_program = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
        reason = "—Ç–∞–∫ –∫–∞–∫ —Ç—ã —É–ø–æ–º—è–Ω—É–ª —Ä–æ–ª–∏ –∏–ª–∏ –æ–±–ª–∞—Å—Ç–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π –∏ –∏–Ω–∂–µ–Ω–µ—Ä–∏–µ–π –ò–ò (ML Engineer, Data Engineer, Computer Vision –∏ —Ç.–¥.)."
    elif ai_product_score > ai_score:
        recommended_program = "AI –∏ ML –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö"
        reason = "—Ç–∞–∫ –∫–∞–∫ —Ç—ã —É–ø–æ–º—è–Ω—É–ª –∏–Ω—Ç–µ—Ä–µ—Å –∫ –ø—Ä–æ–¥—É–∫—Ç–∞–º, –±–∏–∑–Ω–µ—Å—É –∏–ª–∏ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö (AI Product Manager, Data Analyst –∏ —Ç.–¥.)."
    else:
        recommended_program = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
        reason = "—Ç–∞–∫ –∫–∞–∫ —ç—Ç–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∏–º–µ–µ—Ç –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–æ–ª–µ–π –≤ –æ–±–ª–∞—Å—Ç–∏ –ò–ò."

    final_message = RECOMMEND_RESULT_MESSAGE.format(
        background=context.user_data['background'],
        interests=context.user_data['interests'],
        career_goal=context.user_data['career_goal'],
        recommended_program=recommended_program,
        reason=reason
    )
    
    await update.message.reply_text(final_message, parse_mode='Markdown')
    return ConversationHandler.END

async def recommend_cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(RECOMMEND_CANCEL_MESSAGE)
    return ConversationHandler.END

# --- –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –í–û–ü–†–û–°–û–í –° –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï–ú LLM ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."""
    user_question = update.message.text
    logger.info(f"–ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.effective_user.first_name}: {user_question}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    if not model or not index or not chunks:
        await context.bot.send_message(chat_id=update.effective_chat.id, text="–ò–∑–≤–∏–Ω–∏—Ç–µ, –±–æ—Ç –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    if not client:
        await context.bot.send_message(chat_id=update.effective_chat.id, text=NO_LLM_MESSAGE)
        return

    try:
        # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–∞
        question_embedding = model.encode([user_question])
        question_embedding = np.array(question_embedding).astype('float32')

        # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —á–∞–Ω–∫–æ–≤
        k = 3
        distances, indices = index.search(question_embedding, k)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevance_threshold = 80.0 
        best_distance = distances[0][0] if len(distances[0]) > 0 else float('inf')

        # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LLM
        system_prompt = (
            "–í—ã —è–≤–ª—è–µ—Ç–µ—Å—å –ø–æ–ª–µ–∑–Ω—ã–º –ø–æ–º–æ—â–Ω–∏–∫–æ–º –¥–ª—è –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤, –≤—ã–±–∏—Ä–∞—é—â–∏—Ö –º–∞–≥–∏—Å—Ç–µ—Ä—Å–∫–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã "
            "–ò–¢–ú–û '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç' –∏ 'AI –∏ ML –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö'. "
            "–í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. "
            "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å—Å—è –≤ —Ä–∞–∑–¥–µ–ª–µ '–ö–æ–Ω—Ç–µ–∫—Å—Ç'. "
            "–ï—Å–ª–∏ –≤ '–ö–æ–Ω—Ç–µ–∫—Å—Ç–µ' –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å, –≤–µ–∂–ª–∏–≤–æ —Å–æ–æ–±—â–∏—Ç–µ, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—Ç–µ –æ—Ç–≤–µ—Ç–∞. "
            "–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
            "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π—Ç–µ —Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. "
            "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–µ–º–µ –ø—Ä–æ–≥—Ä–∞–º–º –ò–¢–ú–û, –≤–µ–∂–ª–∏–≤–æ —É–∫–∞–∂–∏—Ç–µ –Ω–∞ —ç—Ç–æ."
            "–û—Ç–≤–µ—á–∞–π –ø—Ä–∏–≤–µ—Ç–ª–∏–≤–æ –∏ –≤–µ–∂–ª–∏–≤–æ"
        )

        if best_distance > relevance_threshold:
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω - —Å–æ–æ–±—â–∞–µ–º LLM, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç
            user_prompt = (
                f"–í–æ–ø—Ä–æ—Å –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–∞: {user_question}\n\n"
                f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. "
                f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–µ–∂–ª–∏–≤–æ —Å–æ–æ–±—â–∏—Ç–µ –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç—É, —á—Ç–æ –≤—ã –Ω–µ –º–æ–∂–µ—Ç–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å, "
                f"—Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—ã –ò–¢–ú–û –ø–æ –ò–ò. "
                f"–ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–≥—Ä–∞–º–º–∞—Ö '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç' –∏–ª–∏ 'AI –∏ ML –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö'."
            )
        else:
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω - —Ñ–æ—Ä–º–∏—Ä—É–µ–º –µ–≥–æ –¥–ª—è LLM
            relevant_chunks = [chunks[idx] for i, idx in enumerate(indices[0]) if distances[0][i] <= relevance_threshold]
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context_parts = []
            for chunk in relevant_chunks:
                part = f"–ò—Å—Ç–æ—á–Ω–∏–∫: {chunk['source']}\n–†–∞–∑–¥–µ–ª: {chunk['field']}\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {chunk['text']}"
                context_parts.append(part)
            context_text = "\n\n---\n\n".join(context_parts)

            user_prompt = (
                f"–í–æ–ø—Ä–æ—Å –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–∞: {user_question}\n\n"
                f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context_text}\n\n"
                f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. "
                f"–ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å, —Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ."
            )

        # 3. –í—ã–∑–æ–≤ LLM
        logger.info("–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM...")
        chat_completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            model="gpt-4o-mini", # –ò—Å–ø–æ–ª—å–∑—É–µ–º gpt-4o-mini
            max_tokens=1000,
            temperature=0.2 # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
        )
        logger.info("–û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω.")

        # 4. –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        answer = chat_completion.choices[0].message.content
        await context.bot.send_message(chat_id=update.effective_chat.id, text=answer)

    except AuthenticationError:
        logger.error("–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ OpenAI API.")
        await context.bot.send_message(chat_id=update.effective_chat.id, text=LLM_AUTH_ERROR_MESSAGE)
    except RateLimitError:
        logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI API.")
        await context.bot.send_message(chat_id=update.effective_chat.id, text=LLM_RATE_LIMIT_MESSAGE)
    except APIError as e:
        logger.error(f"–û—à–∏–±–∫–∞ API OpenAI: {e}")
        await context.bot.send_message(chat_id=update.effective_chat.id, text=LLM_API_ERROR_MESSAGE)
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}", exc_info=True)
        await context.bot.send_message(chat_id=update.effective_chat.id, text="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

# --- –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è post_init ---
async def post_init(application: ApplicationBuilder) -> None:
    """–§—É–Ω–∫—Ü–∏—è, –≤—ã–∑—ã–≤–∞–µ–º–∞—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏, –∏–Ω–¥–µ–∫—Å–∞ –∏ –∫–ª–∏–µ–Ω—Ç–∞ API."""
    global model, index, chunks, programs_data, client
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SentenceTransformer...")
    model = SentenceTransformer(MODEL_NAME)
    logger.info("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ FAISS –∏–Ω–¥–µ–∫—Å–∞ –∏ —á–∞–Ω–∫–æ–≤...")
    if os.path.exists(FAISS_INDEX_PATH) and os.path.exists(CHUNKS_PATH):
        index = faiss.read_index(FAISS_INDEX_PATH)
        with open(CHUNKS_PATH, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        logger.info("FAISS –∏–Ω–¥–µ–∫—Å –∏ —á–∞–Ω–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
    else:
        logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ data_processor.py")
        return

    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
    if os.path.exists(DATA_FILE_PATH):
         with open(DATA_FILE_PATH, 'r', encoding='utf-8') as f:
             programs_data = json.load(f)
         logger.info("–î–∞–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
    else:
         logger.warning("–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º –Ω–µ –Ω–∞–π–¥–µ–Ω. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã.")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
    if OPENAI_API_KEY:
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è - –ò–°–ü–†–ê–í–õ–ï–ù–û
            client.models.list() # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            logger.info("–ö–ª–∏–µ–Ω—Ç OpenAI API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω.")
        except AuthenticationError:
            logger.error("–ù–µ–≤–µ—Ä–Ω—ã–π API-–∫–ª—é—á OpenAI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env.")
            client = None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI: {e}")
            client = None
    else:
        logger.warning("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env. –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        client = None

    logger.info("‚úÖ –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞."""
    if not TELEGRAM_BOT_TOKEN:
        logger.error("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –∏ —É–∫–∞–∂–∏—Ç–µ —Ç–æ–∫–µ–Ω.")
        return

    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).post_init(post_init).build()

    # --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ ---
    app.add_handler(CommandHandler("start", start))
    
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler('recommend', recommend_start)],
        states={
            BACKGROUND: [MessageHandler(filters.TEXT & ~filters.COMMAND, recommend_background)],
            INTERESTS: [MessageHandler(filters.TEXT & ~filters.COMMAND, recommend_interests)],
            CAREER: [MessageHandler(filters.TEXT & ~filters.COMMAND, recommend_career)],
        },
        fallbacks=[CommandHandler('cancel', recommend_cancel)],
    )
    app.add_handler(conv_handler)

    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –û–∂–∏–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
    app.run_polling()

if __name__ == '__main__':
    main()
    